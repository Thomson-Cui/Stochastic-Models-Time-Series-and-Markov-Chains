{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency\n",
    "\n",
    "Suppose we observe a time series $\\{x_t\\}$ at times $t_1, \\ldots, t_n$. The distribution of the observed data $x_{t_1}, \\ldots, x_{t_n}$ is characterized by the joint distribution function:\n",
    "\n",
    "$\n",
    "F_{t_1, \\ldots, t_n}(c_1, \\ldots, c_n) = P(x_{t_1} \\leq c_1, \\ldots, x_{t_n} \\leq c_n)\n",
    "$\n",
    "\n",
    "Usually, this is difficult to work with. We may consider the marginal distribution at time $t$:\n",
    "\n",
    "$\n",
    "F_t(x) = P(x_t \\leq x)\n",
    "$\n",
    "\n",
    "or the marginal density:\n",
    "\n",
    "$\n",
    "f_t(x) = \\frac{\\partial F_t(x)}{\\partial x}\n",
    "$\n",
    "\n",
    "assuming this quantity exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mean Function\n",
    "\n",
    "The **mean function** of a time series is:\n",
    "\n",
    "$\n",
    "\\mu_{x_t} = E(x_t)\n",
    "$\n",
    "\n",
    "assuming this expectation exists. Note that the mean is a function of $ t $. When there is no ambiguity about which time series we are referring to, we may instead write $\\mu_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.14 Mean Function of a Moving Average Series\n",
    "\n",
    "$w_t$ denotes a white noise series.\n",
    "- $\\mu_{wt}=E(w_t)=0$\n",
    "\n",
    "$\\mu_{vt}=E(v_t)=\\frac{1}{3}[E(w_{t-1})+E(w_{t})+E(w_{t+1})]=0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.15 Mean Function of a Random Walk with Drift\n",
    "\n",
    "$x_{t} = \\delta\\,t + \\sum_{j=1}^{t}w_{j}, \\qquad t=1,2,\\ldots$\n",
    "- $E(w_t)=0$ for all $t$, and $\\delta$ is a constant.\n",
    "\n",
    "$\\mu_{xt} = \\mathrm{E}(x_{t}) = \\delta\\,t + \\sum_{j=1}^{t}\\mathrm{E}(w_{j}) = \\delta\\,t$\n",
    "\n",
    "which is a straight line with slope $\\delta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.16: Mean Function of Signal Plus Noise\n",
    "\n",
    "$\\begin{aligned}\n",
    "\\mu_{xt} = \\mathrm{E}(x_{t}) \n",
    "&= \\mathrm{E}\\left[2\\cos\\left(2\\pi\\frac{t+15}{50}\\right) + w_{t}\\right] \\\\\n",
    "&= 2\\cos\\left(2\\pi\\frac{t+15}{50}\\right) + \\mathrm{E}(w_{t}) \\\\\n",
    "&= 2\\cos\\left(2\\pi\\frac{t+15}{50}\\right)\n",
    "\\end{aligned}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocovariance Function\n",
    "\n",
    "**Definition 1.2**: The autocovariance function is defined as the product moment\n",
    "\n",
    "$\n",
    "\\gamma_{x}(s,t) = \\operatorname{cov}(x_{s}, x_{t}) = \\operatorname{E}[(x_{s} - \\mu_{s})(x_{t} - \\mu_{t})], \\quad (1.10)\n",
    "$\n",
    "\n",
    "for all $s$ and $t$. When no possible confusion exists about which time series we are referring to, we will drop the subscript and write $\\gamma_{x}(s,t)$ as $\\gamma(s,t)$. Note that $\\gamma_{x}(s,t) = \\gamma_{x}(t,s)$ for all time points $s$ and $t$.\n",
    "\n",
    "- The autocovariance function measures linear dependence in time.\n",
    "- If $x_s$ and $x_t$ are jointly Normally distribution, $\\gamma(s,t)=0$ implies independence."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
