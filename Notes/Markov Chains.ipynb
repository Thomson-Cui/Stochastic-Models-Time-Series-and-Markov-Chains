{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains\n",
    "\n",
    "## 1.1 Definitions and Examples\n",
    "\n",
    "### Definition\n",
    "\n",
    "$X_{n}$ is a discrete time **Markov chain** with **transition matrix** $p(i,j)$ if for any $j,i,i_{n-1},\\ldots i_{0}$\n",
    "\n",
    "\n",
    "$P(X_{n+1}=j|X_{n}=i,X_{n-1}=i_{n-1},\\ldots,X_{0}=i_{0})=p(i,j)\\quad(1.1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more commonly describes a Markov chain by writing down a transition probability $p(i,j)$ with\n",
    "\n",
    "(i) $p(i,j) \\geq 0$, since they are probabilities.\n",
    "\n",
    "(ii) $\\sum_j p(i,j) = 1$, since when $X_n = i$, $X_{n+1}$ will be in some state $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Multistep Transition Probabilities\n",
    "\n",
    "### Theorem 1.1.\n",
    "\n",
    "The $m$ step transition probability $P(X_{n+m}=j|X_n=i)$ is the $m$-th power of the transition matrix $p$.\n",
    "\n",
    "$p^m(i,j) = P(X_{n+m} = j | X_n = i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chapmanâ€“Kolmogorov equation:\n",
    "\n",
    "$p^{m+n}(i,j) = \\sum_k p^m(i,k) p^n(k,j)\\quad(1.2)$\n",
    "\n",
    "*Proof of (1.2):*\n",
    "\n",
    "Breaking things down according to the state at time m,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "p^{m+n}(i,j) \n",
    "&= P(X_{m+n}=j|X_0=i) \\\\\n",
    "&= \\sum_k P(X_{m+n}=j, X_m=k|X_0=i) \\\\\n",
    "&= \\sum_k \\frac{P(X_{m+n}=j, X_m=k, X_0=i)}{P(X_0=i)} \\\\\n",
    "&= \\sum_k \\frac{P(X_{m+n}=j, X_m=k, X_0=i)}{P(X_m=k, X_0=i)} \\cdot \\frac{P(X_m=k, X_0=i)}{P(X_0=i)} \\\\\n",
    "&= \\sum_k P(X_{m+n}=j|X_m=k, X_0=i) \\cdot P(X_m=k|X_0=i) \\\\\n",
    "&= \\sum_k P(X_{m+n}=j|X_m=k) \\cdot P(X_m=k|X_0=i) \\\\\n",
    "&= \\sum_k p^m(i,k) p^n(k,j)\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Classification of States\n",
    "\n",
    "We are often interested in the behavior of the chain for a fixed initial state, so we will introduce the shorthand\n",
    "\n",
    "$P_x(A) = P(A | X_0 = x)$\n",
    "\n",
    "### Stopping Times\n",
    "\n",
    "The stopping time $ T_y $ represents the first return to state $ y $ after time 0, meaning the process must reach $ y $ for the first time at some $ n \\geq 1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_walk(y, steps=1000, num_sim=10000):\n",
    "    T_y_list = []\n",
    "    \n",
    "    for _ in range(num_sim):\n",
    "        x = y\n",
    "        t = 0\n",
    "        \n",
    "        while t < steps:\n",
    "            t += 1\n",
    "            if np.random.rand() < 0.5:\n",
    "                x -= 1 \n",
    "            else:\n",
    "                x += 1  \n",
    "\n",
    "            if x == y and t > 0:\n",
    "                T_y_list.append(t)\n",
    "                break\n",
    "    \n",
    "    return T_y_list\n",
    "\n",
    "y = 2\n",
    "num_sim = 10000\n",
    "T_y = random_walk(y, num_sim=num_sim)\n",
    "\n",
    "plt.hist(T_y, bins=30, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title(f'Distribution of $T_y$ for y={y}')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.2. Strong Markov property\n",
    "\n",
    "Suppose $T$ is a stopping time. Given that $ T = n $ and $ X_T = y $, any other information about $ X_0, \\ldots, X_T $ is irrelevant for predicting the future, and $ X_{T+k}, k \\geq 0 $ behaves like the Markov chain with initial state $ y $.\n",
    "\n",
    "$P(X_{T+1} = z | X_T = y, T = n) = p(y, z)$\n",
    "\n",
    "Let $ V_n $ be the set of vectors $(x_0, \\ldots, x_n)$ so that if $ X_0 = x_0, \\ldots, X_n = x_n $, then $ T = n $ and $ X_T = y $. Breaking things down according to the values of $ X_0, \\ldots, X_n $ gives\n",
    "\n",
    "$V_n = \\{ (x_0, x_1, \\dots, x_n) \\mid X_0 = x_0, X_1 = x_1, \\dots, X_n = x_n \\Rightarrow T = n, X_T = y\\}$\n",
    "\n",
    "$\\Rightarrow P(T = n, X_T = y) = \\sum_{x \\in V_n} P(X_n = x_n, \\dots, X_0 = x_0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "P(X_{T+1} = z, X_T = y, T = n) \n",
    "&= \\sum_{x \\in V_n} P(X_{n+1} = z, X_n = x_n, \\ldots, X_0 = x_0) \\\\\n",
    "&= \\sum_{x \\in V_n} P(X_{n+1} = z | X_n = x_n, \\ldots, X_0 = x_0) P(X_n = x_n, \\ldots, X_0 = x_0)\\\\\n",
    "&= p(y, z) \\sum_{x \\in V_n} P(X_n = x_n, \\ldots, X_0 = x_0) \\\\\n",
    "&= p(y, z) P(T = n, X_T = y)\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing both sides by $P(T = n, X_T = y)$ gives the desired result.\n",
    "\n",
    "Therefore, $P(X_{T+1} = z | X_T = y, T = n) = p(y, z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $p_{yy}=P_y(T_y<\\infty)$ be the probability $X_n$ returns to $y$ when it starts at $y$, and $T_y = \\min\\{n \\geq 1 : X_n = y\\}$.\n",
    "- $p_{yy}=1$, if we don't exclude $n=0 \\Rightarrow T_y = \\min\\{n \\geq 0 : X_n = y\\}$.\n",
    "\n",
    "Let $T_y^1=T_y$ be the time of the first return to $y$, then the time of the $k$-th return to $y$:\n",
    "\n",
    "$T_{y}^{k} = \\min\\{n > T_{y}^{k-1} : X_n = y\\} \\quad (1.3)$ \n",
    "\n",
    "$P_y(T^k_y < \\infty) = p_{yy}^k \\quad (1.4)$\n",
    "\n",
    "(i) $p_{yy} < 1$: The probability of returning $k$ times is $p_{yy}^k \\to 0$ as $k \\to \\infty$. Thus, eventually the Markov chain does not find its way back to $y$. In this case the state $y$ is called **transient**, since after some point it is never visited by the Markov chain.\n",
    "\n",
    "$\\Leftrightarrow P_y(T_y = \\infty)>0\\Leftrightarrow 1-p_{yy}>0$\n",
    "\n",
    "(ii) $p_{yy} = 1$: The probability of returning $k$ times $p_{yy}^k = 1$, so the chain returns to $y$ infinitely many times. In this case, the state $y$ is called **recurrent**, it continually recurs in the Markov chain.\n",
    "\n",
    "$\\Leftrightarrow P_y(T_y = \\infty)=0\\Leftrightarrow 1-p_{yy}=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Œ æ€»ç»“\n",
    "| çŠ¶æ€ç±»åž‹ | å–å€¼èŒƒå›´        | è¯´æ˜Ž                  |\n",
    "|----------|----------------|---------------------|\n",
    "| å¸¸è¿”çŠ¶æ€ | $ \\{1, 2, 3, \\dots\\} $ | ä¸€å®šå›žå¾—æ¥ |\n",
    "| çž¬æ€çŠ¶æ€ | $ \\{1, 2, 3, \\dots\\} \\cup \\{\\infty\\} $ | å¯èƒ½å›žä¸æ¥ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.3.\n",
    "\n",
    "Suppose $ P_x(T_y \\leq k) \\geq \\alpha > 0 $ for all $ x $ in the state space $ S $. Then  \n",
    "\n",
    "$\n",
    "P_x(T_y > nk) \\leq (1 - \\alpha)^n \\to 0 \\text{ as }n\\to\\infty\n",
    "$\n",
    "\n",
    "$\n",
    "P_x(T_y \\leq nk) \\leq 1 - (1 - \\alpha)^n \\to 1 \\text{ as }n\\to\\infty\n",
    "$\n",
    "\n",
    "- $X_0 = x$\n",
    "- $ k $ is a fixed number of steps.  \n",
    "- $ n $ represents how many such $ k $-step blocks we consider.  \n",
    "- $ nk $ is the total number of steps we analyze.  \n",
    "- $ P_x(T_y \\leq k) \\geq \\alpha > 0 \\Rightarrow P_x(T_y > k) \\geq (1-\\alpha)$\n",
    "- $ T_y = \\min\\{ n \\geq 1 : X_n = y \\} $ is the first time the Markov chain reaches state $ y $.  \n",
    "- $ P_x(T_y \\leq k) $ is the probability that the chain reaches $ y $ within at most $ k $ steps, starting from $ x $.  \n",
    "- The assumption $ P_x(T_y \\leq k) \\geq \\alpha > 0 $ means that **from any state $ x $, there is at least a fixed probability $ \\alpha $ of reaching $ y $ within $ k $ steps**.  \n",
    "- $ P_x(T_y > nk) $ is the probability that the chain **has not reached $ y $ after $ nk $ steps**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition 1.1.\n",
    "\n",
    "We say that $ x $ **communicates with** $ y $ and write $ x \\to y $ if there is a positive probability of reaching $ y $ starting from $ x $, that is, the probability  \n",
    "\n",
    "$\n",
    "p_{xy} = P_x(T_y < \\infty) > 0\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.4. \n",
    "If $x\\to y$ and $y\\to z$, then $x\\to z$.\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "Since $x\\to y$ with $m$ steps, $p^m(x,y)>0$.\n",
    "\n",
    "Similarly, $y\\to z$ with $n$ steps, $p^n(y,z)>0$.\n",
    "\n",
    "According to the Chapmanâ€“Kolmogorov equation:\n",
    "\n",
    "$p^{m+n}(i,j) = \\sum_k p^m(i,k) p^n(k,j)\\quad(1.2)$\n",
    "\n",
    "Thus, $p^{m+n}(x,z)=\\sum_k p^m(x,k) p^n(k,z)\\geq p^m(x,y)\\cdot p^n(y,z)>0$.\n",
    "\n",
    "Therefore, $p_{xz}>0$, that is to say: $x\\to z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.5.\n",
    "\n",
    "If $p_{xy}>0$, but $p_{yx}<1$, then $x$ is transient.\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "Let $K=\\min\\{k:p^k(x,y)>0\\}$ be the smallest number of steps we can take to get from $x$ to $y$. Since $p^k(x,y)>0$ there must be a sequence $y_1,...,y_{k-1}$ so that\n",
    "\n",
    "$p(x, y_1) p(y_1, y_2) \\cdots p(y_{k-1}, y) > 0$\n",
    "\n",
    "Since $k$ is minimal all the $y_i\\neq x$ (or there would be a shorter path), and we have\n",
    "\n",
    "$P_x(T_x = \\infty) \\geq p(x, y_1) p(y_1, y_2) \\cdots p(y_{k-1}, y) (1 - p_{yx}) > 0$\n",
    "\n",
    "so $x$ is transient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.6.\n",
    "\n",
    "If $x$ is recurrent and $p_{xy} > 0$, then $p_{yx} = 1$.\n",
    "\n",
    "### Proof:\n",
    "\n",
    "$x$ is recurrent, so $P_x(T_x = \\infty)=0$.\n",
    "\n",
    "$P_x(T_x = \\infty) \\geq p(x, y_1) p(y_1, y_2) \\cdots p(y_{k-1}, y) (1 - p_{yx})$\n",
    "\n",
    "Since $p(x, y_1) p(y_1, y_2) \\cdots p(y_{k-1}, y) > 0$, then\n",
    "\n",
    "$0 \\geq p(x, y_1) p(y_1, y_2) \\cdots p(y_{k-1}, y) (1 - p_{yx})$\n",
    "\n",
    "$\\Rightarrow (1 - p_{yx})\\leq 0$\n",
    "\n",
    "$\\Rightarrow p_{yx}\\geq 1$\n",
    "\n",
    "$\\Rightarrow p_{yx} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.7. \n",
    "If $C$ is a finite **closed and irreducible** set, then all states in $C$ are **recurrent**.\n",
    "- A set $A$ is **closed** if it is impossible to get out, i.e., if $i \\in A$ and $j \\notin A$ then $p(i,j)=0$.\n",
    "    - In following example 1.14: $\\{1,5\\}$,$\\{4,6,7\\}$,$\\{1,4,5,6,7\\}$,$\\{1,3,4,5,6,7\\}$,$\\{1,2,3,4,5,6,7\\}$ are closed sets, but these are too big!\n",
    "- A set $B$ is called **irreducible** if whenever $i,j\\in B, i$ communicates with $j$.\n",
    "    - In following example 1.14: $\\{1,5\\}$ and $\\{4,5,7\\}$ are irreducible closed sets.\n",
    "\n",
    "- Therefore, A set $ C $ is **closed and irreducible** if it satisfies the following conditions:\n",
    "    - For all $ i \\in C $ and $ j \\in S \\setminus C $, we have $ p(i, j) = 0 $ (closedness).\n",
    "    - For all $ i, j \\in C $, there exists a number $ k $ such that $ p^k(i, j) > 0 $ (irreducibility)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof:** To prove theorem 1.7, it is sufficient to prove the following two statements:\n",
    "1. (Lemma 1.9) If $x$ is recurrent and $x \\to y$ then $y$ is recurrent\n",
    "2. (Lemma 1.10) A finite closed set contains at least one recurrent state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1.14 (A Seven-State Chain).** Consider the transition probability:\n",
    "\n",
    "$\n",
    "\\begin{array}{cccccc}\n",
    "  & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\\\\n",
    "1 & .7 & 0 & 0 & 0 & .3 & 0 & 0 \\\\\n",
    "2 & .1 & .2 & .3 & .4 & 0 & 0 & 0 \\\\\n",
    "3 & 0 & 0 & .5 & .3 & .2 & 0 & 0 \\\\\n",
    "4 & 0 & 0 & 0 & .5 & 0 & .5 & 0 \\\\\n",
    "5 & .6 & 0 & 0 & 0 & .4 & 0 & 0 \\\\\n",
    "6 & 0 & 0 & 0 & 0 & 0 & .2 & .8 \\\\\n",
    "7 & 0 & 0 & 0 & 1 & 0 & 0 & 0\n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"..\\\\Images\\\\Theorem 1.7.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.8.\n",
    "\n",
    "If the state space $ S $ is finite, then $ S $ can be written as a disjoint union $ T \\cup R_1 \\cup \\cdots \\cup R_k $, where $ T $ is a set of transient states and the $ R_i $, $ 1 \\leq i \\leq k $, are closed irreducible sets of recurrent states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.9. \n",
    "\n",
    "If $x$ is recurrent and $x \\to y$, then $y$ is recurrent. (Similarly with Lemma 1.6.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.10.\n",
    "\n",
    "In a finite closed set there has to be at least one recurrent state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.11.\n",
    "\n",
    "Let $N(y)$ be the number of visits to $y$ at times $n \\geq 1$, then $E_x N(y) = p_{xy} / (1 - p_{yy})$\n",
    "- $P_x(T_y^k < \\infty) = p_{xy}p_{yy}^{k-1}.\\quad(1.5)$\n",
    "- Using (1.5) we can compute $E_x N(y)$.\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "$EX = \\sum_{k=1}^{\\infty} P(X \\geq k) \\quad(1.6)$\n",
    "\n",
    "For any nonnegative integer valued random variable $X$, Let $1_{\\{X\\geq k\\}}\\sim Bernoulli(p)$, where $p=P(X\\geq k)$, denote the random variable that is $1$ if $X\\geq k$ and 0 otherwise, thus\n",
    "\n",
    "$X=\\sum_{k=1}^\\infty 1_{\\{X\\geq k\\}}$\n",
    "\n",
    "$E(1_{\\{X\\geq k\\}})=P(X\\geq k)$\n",
    "\n",
    "Therefore, we proved (1.6): $EX = \\sum_{k=1}^{\\infty} P(X \\geq k)$.\n",
    "\n",
    "The Probability of returning at least $k$ times, $\\{N(y)\\geq k\\}$, is same as the event that the $k$-th return occurs, i.e., $\\{T_y^k<\\infty\\}$, thus\n",
    "\n",
    "$P_x(N(y)\\geq k)=P_x(T_y^k<\\infty)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "E_xN(y)\n",
    "&=\\sum_{k=1}^\\infty P_x(N(y)\\geq k)\\\\\n",
    "&=\\sum_{k=1}^\\infty P_x(T_y^k<\\infty)\\\\\n",
    "&=\\sum_{k=1}^\\infty p_{xy}p_{yy}^{k-1}\\\\\n",
    "&=p_{xy}\\sum_{k=1}^\\infty p_{yy}^{k-1},\\quad(\\sum_{n=0}^\\infty\\theta^n=1/(1-\\theta))\\\\\n",
    "&=\\frac{p_{xy}}{1-p_{yy}}\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E_x(N(y)) = \\sum_{k=1}^{\\infty} p^k(x, y)$\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "Let's set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$I_{\\{X_n=y\\}}=\n",
    "\\begin{cases}\n",
    "&1\\quad X_n=y\\\\\n",
    "&0\\quad X_n\\neq y\n",
    "\\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$I_{\\{X_n=y\\}}\\sim Bernoulli(p)$, where $p=P_x(X_n=y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N(y)=\\sum_{n=1}^\\infty I_{\\{X_n=y\\}}$\n",
    "\n",
    "$E_xN(y)=\\sum_{n=1}^\\infty P_x(X_n=y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.13.\n",
    "\n",
    "$y$ is recurrent if and only if\n",
    "\n",
    "$\\sum_{n=1}^\\infty p^n(y,y)=E_yN(y)=\\infty$\n",
    "\n",
    "\n",
    "otherwise it is transient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Stationary Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when the initial state is random?\n",
    "\n",
    "Suppose we have an initial state distribution $q$ such that\n",
    "\n",
    "$q(i)=P(X_0=i)$\n",
    "\n",
    "Thus, we can get\n",
    "\n",
    "$P(X_n = j) = \\sum_i P(X_n = j, X_0 = i) = \\sum_i q(i) P(X_n = j \\mid X_0 = i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the social mobility chain with initial distribution\n",
    "\n",
    "$q(1) = .5, q(2) = .2, q(3) = .3$. We can observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{pmatrix} 0.5 & 0.2 & 0.3 \\end{pmatrix} \n",
    "\\begin{pmatrix} 0.7 & 0.2 & 0.1 \\\\ 0.3 & 0.5 & 0.2 \\\\ 0.2 & 0.4 & 0.4 \\end{pmatrix} = \n",
    "\\begin{pmatrix} 0.47 & 0.32 & 0.21 \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the right hand side gives us the distribution of $X_1$ given initial distribution $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition: Stationary distribution\n",
    "\n",
    "$qp=\\sum_i q(i)p(i,j)$\n",
    "\n",
    "If $qp = q$, then $q$ is called a stationary distribution. If the distribution at time 0\n",
    "is the same as the distribution at time 1, then by the Markov property it will be the\n",
    "distribution at all times $n\\geq 1$.\n",
    "\n",
    "We can also use a special letter $\\pi$ to denote solutions of the equation:\n",
    "\n",
    "$\\pi p=\\pi$\n",
    "\n",
    "$\\pi p^n=(\\pi p) p^{n-1}=\\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.17 (Weather Chain). \n",
    "\n",
    "To compute the stationary distribution we want to solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{pmatrix} \\pi_1 & \\pi_2 \\end{pmatrix} \n",
    "\\begin{pmatrix} 0.6 & 0.4 \\\\ 0.2 & 0.8 \\end{pmatrix} = \n",
    "\\begin{pmatrix} \\pi_1 & \\pi_2 \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "&0.6\\pi_1 + 0.2\\pi_2 = \\pi_1 \\\\\n",
    "&0.4\\pi_1 + 0.8\\pi_2 = \\pi_2\\\\\n",
    "&\\pi_1 + \\pi_2 = 1\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "\\pi_1 &= \\frac{0.2}{0.2 + 0.4} = \\frac{1}{3} \\\\\n",
    "\\pi_2 &= \\frac{0.4}{0.2 + 0.4} = \\frac{2}{3}\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.14.\n",
    "\n",
    "Suppose that the $k \\times k$ transition matrix $p$ is irreducible. Then there is a unique solution to $\\pi p = \\pi$ with $\\sum_{x} \\pi_x = 1$ and we have $\\pi_x > 0$ for all $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Limit Behavior\n",
    "\n",
    "### Periodicity\n",
    "\n",
    "The period of a state x is the largest number that will divide all n such that $p^n(x,x)>0$. Or equivalently, **the greatest common divisor** of \n",
    "\n",
    "$I_x=\\{n\\geq 1: p^n(x,x)\\}$\n",
    "\n",
    "çŠ¶æ€ $x$ çš„å‘¨æœŸå®šä¹‰ä¸º $gcd(I_x)$\n",
    "\n",
    "A chain where all states have period 1 is called *aperiodic*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.16:\n",
    "\n",
    "If $x$ has period 1, then there is a number $n_0$ such that $n\\in I_x$ for all $n\\geq n_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.17:\n",
    "\n",
    "If $p(x,x)>0$ then $x$ has period 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1.18:\n",
    "\n",
    "If $p_{xy}>0$ and $p_{yx}>0$ then $x$ and $y$ have the same period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Main Results**\n",
    "\n",
    "We will now state our main results about the limiting behavior of a Markov chain. Our theorems will rely on some subset of the following four assumptions:\n",
    "\n",
    "1. $ I: p $ is irreducible  \n",
    "2. $ A: $ aperiodic, all states have period 1  \n",
    "3. $ R: $ all states are recurrent  \n",
    "4. $ S: $ there is a stationary distribution $\\pi$\n",
    "\n",
    "We will use these abbreviations for conciseness in stating our theorems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.19 (Convergence Theorem):\n",
    "\n",
    "Suppose $I,A,S$. Then as $n\\to\\infty, p^n(x,y)\\to\\pi(y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "ä½¿ç”¨ä¹‹å‰è®¨è®ºçš„é“¾ï¼š\n",
    "$\n",
    "P = \\begin{bmatrix}\n",
    "0.6 & 0.4 \\\\\n",
    "0.3 & 0.7\n",
    "\\end{bmatrix}\n",
    "$\n",
    "- **$ I $**ï¼šä¸å¯çº¦ï¼ˆçŠ¶æ€ 1 å’Œ 2 äº’ç›¸å¯è¾¾ï¼‰ã€‚\n",
    "- **$ A $**ï¼šéžå‘¨æœŸæ€§ï¼ˆçŠ¶æ€ 1 å’Œ 2 çš„å‘¨æœŸä¸º 1ï¼Œ$ I_x = \\{1, 2, 3, \\dots\\} $ï¼ŒGCD = 1ï¼‰ã€‚\n",
    "- **$ S $**ï¼šå­˜åœ¨å¹³ç¨³åˆ†å¸ƒ $ \\pi = [4/7, 3/7] $ï¼Œæ»¡è¶³ $ \\pi P = \\pi $ å’Œ $ \\pi(1) + \\pi(2) = 1 $ã€‚\n",
    "- æ ¹æ® Theorem 1.19ï¼š\n",
    "  - $ p^n(1, 1) \\to \\pi(1) = 4/7 \\approx 0.571 $ã€‚\n",
    "  - $ p^n(1, 2) \\to \\pi(2) = 3/7 \\approx 0.429 $ã€‚\n",
    "  - ç±»ä¼¼åœ°ï¼Œ$ p^n(2, 1) \\to 4/7 $ï¼Œ$ p^n(2, 2) \\to 3/7 $ã€‚\n",
    "- æ”¶æ•›æ˜¯å•è°ƒçš„ã€æ— æŒ¯è¡çš„ï¼Œå› ä¸ºé“¾éžå‘¨æœŸæ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stationary measure\n",
    "\n",
    "A vector $\\mu$ is a stationary measure if\n",
    "\n",
    "$\\sum_x \\mu(x) p(x, y) = \\mu(y)$\n",
    "\n",
    "Unlike $\\pi$, $\\mu$ is not required to be a distribution, though if the state space is finite we can find $\\pi$ by normalizing $\\mu$:\n",
    "\n",
    "$\n",
    "\\pi(x) = \\frac{\\mu(x)}{\\sum_x \\mu(x)}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.20:\n",
    "\n",
    "Suppose $I,R.$ Then there is a stationary measure $\\mu$ such that $\\mu(x)>0$ for all $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.21 (Asymptotic Fequency): \n",
    "\n",
    "Suppose $I,R.$ Let $N_n(y)$ be the number of visits to $y$ up to time $n$. Then\n",
    "\n",
    "$\\frac{N_n(y)}{n}\\to\\frac{1}{E_y(T_y)}$\n",
    "\n",
    "- $\\frac{N_n(y)}{n}$ is the frequency to visit $y$\n",
    "- $E_y(T_y)$ is expected the first return from $y$ to $y$\n",
    "\n",
    "We will see later that if $E_y(T_y)=\\infty$ then $\\frac{N_n(y)}{n}\\to 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.22:\n",
    "\n",
    "Suppose $I,S$. Then\n",
    "\n",
    "$\\pi(y)=\\frac{1}{E_y(T_y)}$\n",
    "\n",
    "and thus the stationary distribution is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.23:\n",
    "\n",
    "Suppose $I,S$ and $\\sum_{x} |f(x)|\\pi(x)<\\infty$ then\n",
    "\n",
    "$\\frac{1}{n}\\sum_{m=1}^{n}f(X_m)\\to \\sum_{x}f(x)\\pi(x)$\n",
    "\n",
    "Note that Theorems 1.21 and 1.23 do not require aperiodicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Store inventory \n",
    "\n",
    "Suppose a game store sells PS5s, and each day there is demand for 0, 1, 2, or 3 PS5s with probabilities .3, .4, .2, and .1. Each sale produces a profit of $120, but it costs $20 a day to keep unsold units stocked.\n",
    "\n",
    "The store adopts the following stocking policy: if there are less than 3 units, restock to 3 to start the next day.\n",
    "\n",
    "Let $X_n=$ $\\{0,1,2,3\\}$ be the number of units sold each day. \n",
    "\n",
    "##### What is the transition matrix?\n",
    "\n",
    "$P = \\begin{bmatrix}\n",
    "0.3 & 0.4 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.2 & 0.1 \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What's the stationary distribution of $X_n$?\n",
    "\n",
    "$\\pi(0)=0.3$\n",
    "\n",
    "$\\pi(1)=0.4$\n",
    "\n",
    "$\\pi(2)=0.2$\n",
    "\n",
    "$\\pi(3)=0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What's the long run sales profit?\n",
    "\n",
    "According to Theorem 1.23: $I,S$ and $\\sum_{x} |f(x)|\\pi(x)<\\infty$ then\n",
    "\n",
    "$\\frac{1}{n}\\sum_{m=1}^{n}f(X_m)\\to \\sum_{x}f(x)\\pi(x)$\n",
    "\n",
    "æˆ‘ä»¬éœ€è¦å®šä¹‰æ¯æ—¥åˆ©æ¶¦å‡½æ•° $f(X_n)$, åŸºäºŽé”€å”®æ•°é‡\n",
    "\n",
    "$f(X_m)=120\\cdot X_m=f(x)$\n",
    "\n",
    "é•¿æœŸé”€å”®æ”¶å…¥$\\frac{1}{n}\\sum_{m=1}^{n}f(X_m)$:\n",
    "\n",
    "$\\sum_{x}f(x)\\pi(x)=0\\cdot 120\\cdot 0.3+ 1\\cdot 120\\cdot 0.4+ 2\\cdot 120\\cdot 0.2+3\\cdot 120\\cdot 0.1=132$\\$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the long run inventory holding cost?\n",
    "\n",
    "$h(X_m)=20\\cdot(3-X_m)$\n",
    "\n",
    "$\\sum_{x}h(x)\\pi(x)=20\\cdot 3\\cdot 0.3+ 20\\cdot 2\\cdot 0.4 + 20\\cdot 1\\cdot 0.2+ 20\\cdot 0\\cdot 0.1=38$\\$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the long run net profit?\n",
    "\n",
    "132-38=94$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: store inventory\n",
    "\n",
    "Suppose instead the stocking policy is as follows: if there are less than 2 units, restock to 3 to start the next day.\n",
    "\n",
    "$P = \\begin{bmatrix}\n",
    "0.3 & 0.4 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.3 & 0 \\\\\n",
    "0.3 & 0.4 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.2 & 0.1 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Find the stationary distribution, $\\pi p =\\pi$\n",
    "\n",
    "$\\pi=(19/110\\quad 30/110\\quad 40/110\\quad 21/110)$\n",
    "\n",
    "We can apply Theorem 1.23 to compare the long run performance of the two stocking policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the long run sales profit?\n",
    "\n",
    "$\\sum_{x}f(x)\\pi(x)=127.64$\\$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the long run inventory holding cost?\n",
    "\n",
    "$\\sum_{x}h(x)\\pi(x)=31.45$\\$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the long run net profit?\n",
    "\n",
    "$127.64-31.45=46.19$\\$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemma 1.26:\n",
    "\n",
    "If there is a stationary distribution $\\pi$, then all states $y$ such that $\\pi(y)>0$ are recurrent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Special Examples\n",
    "\n",
    "### 1.6.1 Doubly stochastic chains\n",
    "\n",
    "**Definition 1.2.** \n",
    "\n",
    "A transition matrix $p$ is said to be doubly stochastic if its COLUMNS sum to 1, or in symbols $\\sum_x p(x,y)=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example: Symmetric reflecting random walk\n",
    "\n",
    "Consider the state space $\\{0, 1, \\ldots, L\\}$ and let  \n",
    "\n",
    "$X_t = \\max(X_{t-1} - 1, 0) \\text{ with probability } 1/2$\n",
    "\n",
    "$X_t = \\min(X_{t-1} + 1, L) \\text{ with probability } 1/2$\n",
    "\n",
    "Suppose $L=4$, transition matrix:\n",
    "\n",
    "$\\begin{array}{llllll} \n",
    "& 0 & 1 & 2 & 3 & 4 \\\\\n",
    "0 & 1 / 2 & 1 / 2 & 0 & 0 & 0 \\\\\n",
    "1 & 1 / 2 & 0 & 1 / 2 & 0 & 0 \\\\\n",
    "2 & 0 & 1 / 2 & 0 & 1 / 2 & 0 \\\\\n",
    "3 & 0 & 0 & 1 / 2 & 0 & 1 / 2 \\\\\n",
    "4 & 0 & 0 & 0 & 1 / 2 & 1 / 2\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1.24:\n",
    "\n",
    "If $p$ is doubly stochastic transition matrix for a Markov chain with $N$ states, then $\\pi(x)=1/N$ for all $x$ is a stationary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example: Tiny Board Game  \n",
    "\n",
    "Suppose you play a board game with spaces labeled $\\{0, 1, 2, 3, 4, 5\\}$. Each turn you roll a die that has 3 sides with 1, 2 sides with 2, 1 side with 3, and move that number of spaces. On the board, 5 is adjacent to 0 so that if you are currently on space $i$ and move $j$ spaces, the result is that you end on space $i + j$ mod 5. What is the transition matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{array}{lllllll} \n",
    "& 0 & 1 & 2 & 3 & 4 & 5\\\\\n",
    "0 & 0 & 1 / 2 & 1/3 & 1/6 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & 1 / 2 & 1/3 & 1/6 & 0 \\\\\n",
    "2 & 0 & 0 & 0 & 1 / 2 & 1/3 & 1/6 \\\\\n",
    "3 & 1/6 & 0 & 0 & 0 & 1 / 2 & 1/3\\\\\n",
    "4 & 1/3 & 1/6 & 0 & 0 & 0 & 1/2 \\\\\n",
    "5 & 1/2 & 1/3 & 1/6 & 0 & 0 & 0 \n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Balance Condition\n",
    "\n",
    "$\\pi$ is said to satisfy the detailed balance condition for a transition matrix $p$ if for all $x,y$\n",
    "\n",
    "$\\pi(x)p(x,y)=\\pi(y)p(y,x)$\n",
    "\n",
    "Note that this is stronger than $\\pi p=\\pi$:\n",
    "\n",
    "$\\sum_x\\pi(x)p(x,y)=\\pi(y)\\sum_x p(y,x)=\\pi(y)$ (è¿™æ˜¯å¹³ç¨³åˆ†å¸ƒçš„å®šä¹‰)\n",
    "\n",
    "$\\pi$ satisfies the detailed balance condition $\\Rightarrow$ $\\pi$ satisfies stationary distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Consider the following transition matrix:\n",
    "\n",
    "|   | 1   | 2   | 3   |\n",
    "|---|-----|-----|-----|\n",
    "| 1 | 0.5 | 0.5 | 0   |\n",
    "| 2 | 0.3 | 0.1 | 0.6 |\n",
    "| 3 | 0.2 | 0.4 | 0.4 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®ƒæ»¡è¶³ stationary distribution, since åˆ—ä¹‹åˆç­‰äºŽ1ï¼Œ$\\pi=(1/3,1/3,1/3)$ã€‚ä¸æ»¡è¶³ Detailed Balance Condition, å› ä¸ºé€šè¿‡è®¡ç®— $\\pi(1)p(1,3)=\\pi(3)p(3,1)$ æˆ‘ä»¬å¾—å‡º $\\pi(3)=0$ ä¸Žäº‹å®žä¸ç¬¦ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Ehrenfest Chain\n",
    "\n",
    "Consider the Ehrenfest chain with 3 balls so the transition matrix is\n",
    "\n",
    "$\\begin{array}{cccc}\n",
    " & 0 & 1 & 2 & 3 \\\\\n",
    "0 & 0 & 3/3 & 0 & 0 \\\\\n",
    "1 & 1/3 & 0 & 2/3 & 0 \\\\\n",
    "2 & 0 & 2/3 & 0 & 1/3 \\\\\n",
    "3 & 0 & 0 & 3/3 & 0 \\\\\n",
    "\\end{array}$\n",
    "\n",
    "What is $\\pi$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Birth and death chains: $\\pi(x+1) = \\frac{p_x}{q_{x+1}} \\cdot \\pi(x)$\n",
    "\n",
    "$\\begin{array}{ll}\n",
    "p(x, x+1) = p_x & \\text{for } x < r \\\\\n",
    "p(x, x-1) = q_x & \\text{for } x > \\ell \\\\\n",
    "p(x, x) = 1 - p_x - q_x & \\text{for } \\ell \\leq x \\leq r\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $\\pi(0)=c$, thus $\\pi(1)=3c,\\pi(2)=3c, \\pi(3)=c$\n",
    "\n",
    "$\\sum_x\\pi(x)=1,c=1/8$\n",
    "\n",
    "$\\pi(0)=1/8$, thus $\\pi(1)=3/8,\\pi(2)=3/8, \\pi(3)=1/8$\n",
    "\n",
    "Verify $\\pi(x)p(x,y)=\\pi(y)p(y,x),\\forall x,y$, sucessfully:\n",
    "\n",
    "$\\pi$ satisfies stationary distribution.\n",
    "\n",
    "$\\pi$ satisfies the detailed balance condition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reversibility\n",
    "\n",
    "Consider a Markov Chain with transition matrix $p(i,j)$ and stationary distribution $\\pi$. What happens if we watcg the process $X_m,0\\leq m\\leq n$ in reverse?\n",
    "\n",
    "**Theorem 1.25:** Fix $ n $ and let $ Y_m = X_{n-m} $ for $ 0 \\leq m \\leq n $. Then  \n",
    "\n",
    "$ Y_m $ is a Markov chain with transition probability  \n",
    "\n",
    "$\n",
    "\\hat{p}(i,j) = P(Y_{m+1} = j|Y_m = i) = \\frac{\\pi(j)p(j,i)}{\\pi(i)}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that $\\hat{p}(i,j)$ defines a valid transition matrix:\n",
    "\n",
    "$\\hat{p}(i,j)=\\frac{\\pi(j)p(j,i)}{\\pi(i)}$\n",
    "\n",
    "$\\sum_j \\frac{\\pi(j) p(j,i)}{\\pi(i)}=\\frac{1}{\\pi(i)}\\sum_j \\pi(j) p(j,i)=\\frac{1}{\\pi(i)}(\\pi(i))=1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if $\\pi$ satisfies the detailed balance condition?\n",
    "\n",
    "$\\pi(j)p(j,i)=\\pi(i)p(i,j),\\forall i,j$\n",
    "\n",
    "$\\hat{p}(i,j)=\\frac{\\pi(j)p(j,i)}{\\pi(i)}=\\frac{\\pi(i)p(i,j)}{\\pi(i)}=p(i,j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\pi$ satisfies the detailed balance condition, we see that $Y_m$ has the same distribution as $X_n$.\n",
    "\n",
    "A Markov chain with this property (that the distribution is the same when the chain is reversed) is called **reversible**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detailed balance condition is a sufficient, but not necessary condiction for a Markov chain to be reversible.\n",
    "- The detailed balance condition $\\Rightarrow$ Markov chain to be reversible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hasting Algorithm\n",
    "\n",
    "The Metropolis-Hasting algorithm is an algorithm for sampling\n",
    "from a distribution $\\pi(x)$.\n",
    "\n",
    "The Metropolis-Hasting algorithm is important in Bayesian\n",
    "statistics as it is commonly used to sample from a posterior\n",
    "distribution in MCMC (Markov chain Monte Carlo) methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with a Markov chain with transition matrix $ q(x, y) $ that we call the proposal distribution. We wish to generate a sequence $ X_1, \\ldots, X_N $ in the following way. Given $ X_n = x $, we propose the next move $ y $ according to $ q(x, y) $. Next, we define\n",
    "\n",
    "$\n",
    "r(x, y) = \\min\\left(1, \\frac{\\pi(y) q(y, x)}{\\pi(x) q(x, y)}\\right)\n",
    "$\n",
    "\n",
    "We then flip a coin with probability of heads $ r(x, y) $:\n",
    "\n",
    "- If heads, set $ X_{n+1} = y $ (accept the new move).\n",
    "- If tails, set $ X_{n+1} = x $ (reject the new move)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the sequence $ X_1, \\ldots, X_N $ in this way results in a Markov chain with transition probabilities\n",
    "\n",
    "$\n",
    "p(x, y) = q(x, y) r(x, y)\n",
    "$\n",
    "\n",
    "We can verify that the distribution $\\pi$ satisfies **the detailed balance condition** for $ p(x, y) $:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that $\\pi(y)q(y,x) > \\pi(x)q(x,y)$. In this case:\n",
    "\n",
    "$\\pi(x)p(x,y) = \\pi(x)q(x,y) \\cdot 1$\n",
    "\n",
    "$\\pi(y)p(y,x) = \\pi(y)q(y,x) \\frac{\\pi(x)q(x,y)}{\\pi(y)q(y,x)} = \\pi(x)q(x,y) = \\pi(x)p(x,y)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate samples from $\\pi(x)$\n",
    "\n",
    "1. Run the chain defined by $p(x, y)$ for a long time until it reaches equilibrium to obtain a single sample.\n",
    "2. Repeat 1. by taking samples at widely separated times.\n",
    "\n",
    "The question of how long is a sufficiently \"long time\" is not always easy to answer.\n",
    "\n",
    "We can also use Theorem 1.23 to compute expected values of functions of $X \\sim \\pi(x)$, since this theorem tells us\n",
    "\n",
    "$\n",
    "\\frac{1}{n}\\sum_{m=1}^{n} f(X_m) \\to \\sum_{x} f(x)\\pi(x)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Geometric distribution\n",
    "\n",
    "Consider the geometric distribution with success probability $\\theta$, so\n",
    "\n",
    "$\\pi(x)=\\theta(1-\\theta)^{x-1},x=1,2,...$\n",
    "\n",
    "$q(x,y)=\n",
    "\\begin{cases}\n",
    "1/2 \\quad & |x-y|=1 \\\\\n",
    "0   \\quad & otherwise\n",
    "\\end{cases}$\n",
    "\n",
    "$r(x,y)=\n",
    "\\begin{cases}\n",
    "\\frac{\\theta(1-\\theta)^{y-1}}{\\theta(1-\\theta)^{x-1}} \\quad & |x-y|=1\\\\\n",
    "0   \\quad & otherwise\n",
    "\\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the Metropolis-Hastings Algorithm useful in Bayesian statistics?\n",
    "\n",
    "Consider the problem of inference for a parameter Î¸ after observing data\n",
    "\n",
    "$Y_1,...,Y_n\\sim$ iid $f(y|\\theta)$\n",
    "\n",
    "Bayesian statistics begins with a prior distribution on $\\theta, h(\\theta)$, and expresses belief about the parameter $\\theta$ after observing the data by the posterior\n",
    "\n",
    "$g(\\theta|Y_1,...,Y_n)=\\frac{f(\\mathbf{Y}|\\theta)h(\\theta)}{\\sum_\\theta f(\\mathbf{Y}|\\theta)h(\\theta)}$\n",
    "\n",
    "However, in many cases the denominator $\\sum_\\theta f(\\mathbf{Y}|\\theta)h(\\theta)$ is difficult to compute. In particular, if $\\theta$ is a high dimensional quantity or if $\\theta$ takes on continuous values in which case we replace the sum by an integral and \n",
    "\n",
    "$\\int_\\theta f(\\mathbf{Y}|\\theta)h(\\theta)$\n",
    "\n",
    "may not have a closed form solution\n",
    "\n",
    "To see why Metropolis-Hastings is useful here, set\n",
    "\n",
    "$\\pi(\\theta)=\\frac{f(\\mathbf{Y}|\\theta)h(\\theta)}{\\sum_\\theta f(\\mathbf{Y}|\\theta)h(\\theta)}$\n",
    "\n",
    "Now for any $q(\\theta,\\theta')$ we might choose we can observe\n",
    "\n",
    "$r(\\theta,\\theta')=\\min\\big(\\frac{\\pi(\\theta')q(\\theta',\\theta)}{\\pi(\\theta)q(\\theta,\\theta')},1\\big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: \n",
    "Suppose $k$-sided die is rolled $10$ times. $k$ is unknown, but a priori we believe $P(k = 4) = P(k = 6) = P(k = 8) = 1/3$. Of the $10$ rolls, $4$ are $1s$. What is the posterior distribution of $k$?\n",
    "\n",
    "$\\begin{aligned}\n",
    "P(k|x=4)=\\frac{P(x=4|k)P(k)}{\\sum_{k\\in\\{4,6,8\\}}P(x=4|k)P(k)}=\\pi(k|x=4)\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we use the M-H algorithm to sample from the posterior of $k=\\theta$?\n",
    "\n",
    "$q(\\theta,\\theta')=\n",
    "\\begin{cases}\n",
    "1/3\\quad &\\theta'=4,6,8\\\\\n",
    "0\\quad &otherwise\n",
    "\\end{cases}$\n",
    "\n",
    "$r(\\theta,\\theta')=\\min(\\frac{\\pi(\\theta')q(\\theta',\\theta)}{\\pi(\\theta)q(\\theta,\\theta')},1)=\\min(\\frac{P(x=4|k=\\theta')P(k=\\theta')q(\\theta',\\theta)}{P(x=4|k=\\theta)P(k=\\theta)q(\\theta,\\theta')},1)=\\min(\\frac{\\binom{10}{4}(1/\\theta')^4(1-1/\\theta')^6\\cdot (1/3)\\cdot (1/3)}{\\binom{10}{4}(1/\\theta)^4(1-1/\\theta)^6\\cdot (1/3)\\cdot (1/3)},1)=\\min(\\frac{(1/\\theta')^4(1-1/\\theta')^6}{(1/\\theta)^4(1-1/\\theta)^6},1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Exit Distribution\n",
    "\n",
    "### Example: 2 years college \n",
    "\n",
    "At a local two year college, 60% of fresh men become sophomores, 25% remain freshmen, and 15% drop out. 70% of sophomores graduate and transfer to a four year college, 20% remain sophomores and 10% drop out. What fraction of new students eventually graduate?\n",
    "\n",
    "Letâ€™s begin with the transition matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{array}{cccc}\n",
    "& 1 & 2 & G & D \\\\\n",
    "1 & 0.25 & 0.6 & 0 & 0.15 \\\\\n",
    "2 & 0 & 0.2 & 0.7 & 0.1 \\\\\n",
    "G & 0 & 0 & 1 & 0 \\\\\n",
    "D & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the fraction of new students eventually graduate?\n",
    "- Let $h(x)$ be the probability that a student currently in state $x$ eventually graduates.\n",
    "\n",
    "    $h(1)=0.25h(1)+0.6h(2)$\n",
    "\n",
    "    $h(2)=0.2h(2)+0.7$\n",
    "\n",
    "    $h(1)=0.7$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.40. Tennis. \n",
    "\n",
    "In tennis the winner of a game is the first player to win four points, unless the score is 4âˆ’3, in which case the game must continue until one player is ahead by two points and wins the game. Suppose that the server win the point with probability 0.6 and successive points are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{array}{cc|cccc}\n",
    " & 2 & 1 & 0 & -1 & -2 \\\\\n",
    "2 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "\\hline\n",
    "1 & .6 & 0 & .4 & 0 & 0 \\\\\n",
    "0 & 0 & .6 & 0 & .4 & 0 \\\\\n",
    "-1 & 0 & 0 & .6 & 0 & .4 \\\\\n",
    "\\hline\n",
    "-2 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let $h(x)$ be the probability of the server winning when the score is $x$ then\n",
    "\n",
    "    $h(x)=\\sum_y p(x,y)h(y)$\n",
    "\n",
    "    where $h(2)=1$ and $h(-2)=0$.\n",
    "\n",
    "    $h(1) = .6 + .4h(0)$\n",
    "\n",
    "    $h(0) = .6h(1) + .4h(-1)$\n",
    "\n",
    "    $h(-1) = .6h(0)$\n",
    "\n",
    "    $h(0) = 0.6923, h(1)=0.8769, h(-1)=0.4154$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- General case: What if the serving player wins each point with probability $w$?\n",
    "\n",
    "    Suppose that the server wins each point with probability $w$\n",
    "\n",
    "    If at this time, the game is tied, after $2$ points, the server will have won with probability $w^2$, lose with $(1-w)^2$, and returned to a tied game with probability $2w(1-w)$, so $h(0)=w^2+2w(1-w)h(0)$.\n",
    "\n",
    "    $h(0)=\\frac{w^2}{w^2+(1-w)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 1.27:** Suppose $ X_n $ is a Markov chain on a finite state space $ S $. Let $ a, b \\in S $, $ C = S - \\{a, b\\} $, and  \n",
    "$ V_x = \\min\\{n \\geq 1, X_n = x\\} $ for each $ x \\in S $. Suppose  \n",
    "$ h(a) = 1, h(b) = 0 $, and  \n",
    "\n",
    "$\n",
    "h(x) = \\sum_y p(x, y)h(y)\n",
    "$\n",
    "\n",
    "Then if $ P_x(\\min\\{V_a, V_b\\} < \\infty) > 0 $ for all $ x \\in C $, then  \n",
    "\n",
    "$\n",
    "h(x) = P_x(V_a < V_b)\n",
    "$\n",
    "- $h(x)$ æ˜¯ä»ŽçŠ¶æ€ $x$ å¼€å§‹ï¼Œé“¾å…ˆåˆ°è¾¾ $a$ è€Œä¸æ˜¯ $b$ çš„æ¦‚çŽ‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Bob, who has 15 pennies, and Charlie, who has 10 pennies, decide to play a game. They each flip a coin. If the two coins match, Bob gets the two pennies (for a profit of 1). If the two coins are different, then Charlie gets the two pennies. They quit when someone has all the pennies. What is the probability Bob will eventually have all the pennies?\n",
    "\n",
    "Let $ X_n $ be the number of pennies Bob has after $ n $ rounds. Note this is a fair game in the sense that\n",
    "\n",
    "$E_x(X_1)=0.5(x+1)+0.5(x-1)=x$\n",
    "\n",
    "The expected number he has at the end of the game should be the same as at the begining so:\n",
    "\n",
    "$x=NP_x(V_N<V_0)+0P_x(V_0<V_N)$\n",
    "\n",
    "$P_x(V_N<V_0)=h(x)=x/N$\n",
    "\n",
    "To prove this note that by considering what happens on the first step\n",
    "\n",
    "$h(x)=0.5h(x+1)+0.5h(x-1)$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$h(x+1)-h(x)=h(x)-h(x-1)$\n",
    "\n",
    "It means, $h$ has costant slope and $h(0)=0$ and $h(N)=1$, so $h(x)=x/N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of an unfair game we return to our Gambler's Ruin. Suppose we have a Gambler's Ruin with $ N $ and $ p \\neq 1/2 $. We can consider the probability that starting from $ \\$x $, the gambler reaches $ \\$N $ before going bankrupt. We will let\n",
    "\n",
    "$\n",
    "h(x) = P(V_N < V_0)\n",
    "$\n",
    "\n",
    "and note that $ h(N) = 1 $ and $ h(0) = 0 $. We now consider $ h(x) $ for $ 0 < x < N $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h(x)=p(h(x+1))+(1-p)h(x-1)$\n",
    "\n",
    "$h(x+1)-h(x)=\\frac{1-p}{p}(h(x)-h(x-1))$\n",
    "\n",
    "$c=h(1)-h(0)=h(1)$\n",
    "\n",
    "$h(x+1)-h(x)=c(\\frac{1-p}{p})^{x}$\n",
    "\n",
    "$\\sum_{x=0}^{N-1}(h(x+1)-h(x))=h(N)-h(0)=1$\n",
    "\n",
    "$\\sum_{x=0}^n a^x=\\frac{1-a^{n+1}}{1-a}$\n",
    "\n",
    "$\\theta = \\frac{1-p}{p}$\n",
    "\n",
    "$\\sum_{x=0}^{N-1}(h(x+1)-h(x))=c\\sum_{x=0}^{N-1}(\\frac{1-p}{p})^{x}=c\\cdot\\frac{1-\\theta^N}{1-\\theta} = 1$\n",
    "\n",
    "$c=\\frac{1-\\theta}{1-\\theta^N}$\n",
    "\n",
    "$h(x)-h(0)=c\\cdot\\frac{1-\\theta^x}{1-\\theta}$\n",
    "\n",
    "$h(x)=\\frac{(\\frac{1-p}{p})^x-1}{(\\frac{1-p}{p})^N-1}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of an unfair game we return to our Gambler's Ruin. Suppose we have a Gambler's Ruin with $ N $ and $ p \\neq 1/2 $. We can consider the probability that starting from $ \\$x $, the gambler reaches $ \\$N $ before going bankrupt. We will let\n",
    "\n",
    "$\n",
    "h(x) = P(V_N < V_0)\n",
    "$\n",
    "\n",
    "and note that $ h(N) = 1 $ and $ h(0) = 0 $. We now consider $ h(x) $ for $ 0 < x < N $.\n",
    "\n",
    "$\\theta=(1-p)/p=10/9$\n",
    "\n",
    "$h(x=50)=\\frac{(10/9)^{50}-1}{(10/9)^{100}-1}=0.005128$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Exit Times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1.45. Two year college.** In Example 1.39 we introduced a Markov chain with state space $ 1 = \\text{freshman}, \\, 2 = \\text{ sophomore}, \\, G = \\text{graduate}, \\, D = \\text{dropout}, $ and transition probability\n",
    "\n",
    "$\n",
    "\\begin{array}{ccccc}\n",
    "& 1 & 2 & G & D \\\\\n",
    "1 & 0.25 & 0.6 & 0 & 0.15 \\\\\n",
    "2 & 0 & 0.2 & 0.7 & 0.1 \\\\\n",
    "G & 0 & 0 & 1 & 0 \\\\\n",
    "D & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "On the average how many years does a student take to graduate or drop out?\n",
    "\n",
    "Let $ g(x) $ è¡¨ç¤ºä»ŽçŠ¶æ€ $x$ å¼€å§‹ï¼Œåˆ°è¾¾å¸æ”¶çŠ¶æ€ï¼ˆæ¯•ä¸š$G$æˆ–è¾å­¦$D$ï¼‰çš„æœŸæœ›æ—¶é—´. $ g(G) = g(D) = 0 $. By considering what happens on one step\n",
    "\n",
    "$\n",
    "g(1) = 1 + 0.25g(1) + 0.6g(2)\n",
    "$\n",
    "\n",
    "$\n",
    "g(2) = 1 + 0.2g(2)\n",
    "$\n",
    "\n",
    "æ—¶é—´åŠ 1ï¼ˆå› ä¸ºæ¯ä¸€æ­¥ä»£è¡¨ä¸€å¹´ï¼‰. To solve for $ g $, we note that the second equation implies $ g(2) = 1/0.8 = 1.25 $ and then the first that\n",
    "\n",
    "$\n",
    "g(1) = \\frac{1 + 0.6(1.25)}{0.75} = \\frac{1.75}{0.75} = 2.3333\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a Markov chain $ X_n $ on a state space $ S $ with one or more absorbing states, we might be interested in the time until $ X_n $ eventually reaches some absorbing state $ a $.\n",
    "\n",
    "We will call this the **exit time**. For now we will consider another example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: In a game of tennis, the first player to 4 points wins, with the stipulation that one must win by at least 2 point. Suppose a game of tennis is tied 3-3, the serving player wins each point, and successive points are independent. What is the expected time until the game ends?\n",
    "\n",
    "$\\begin{array}{cc|cccc}\n",
    " & 2 & 1 & 0 & -1 & -2 \\\\\n",
    "2 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "\\hline\n",
    "1 & .6 & 0 & .4 & 0 & 0 \\\\\n",
    "0 & 0 & .6 & 0 & .4 & 0 \\\\\n",
    "-1 & 0 & 0 & .6 & 0 & .4 \\\\\n",
    "\\hline\n",
    "-2 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Theorem 1.28:** \n",
    "\n",
    "Let $ X_n $ be a Markov chain on finite state space $ S $. Let $ A \\subset S $ and $ V_a = \\inf\\{n \\geq 0 : X_n \\in A\\} $. Suppose $ C = S - A $ is finite and $ P_X(V_a < \\infty) > 0 $ for all $ x \\in C $. Let $ g(a) = 0 $ for all $ a \\in A $ and for all $ x $ in $ C $\n",
    "\n",
    "$\n",
    "g(x) = 1 + \\sum_y p(x, y)g(y)\n",
    "$\n",
    "\n",
    "Then $ g(x) = E_X(V_A) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example: Waiting time for TT** \n",
    "\n",
    "Suppose we flip a fair coin repeatedly. Let $T_{TT}$ be the (random) number of flips needed to observe two tails in a row. We want to find $E(T_{TT})$.\n",
    "\n",
    "$\\begin{array}{c|ccc}\n",
    " & 0 & 1 & 2 \\\\\n",
    "\\hline\n",
    "0 & 1/2 & 1/2 & 0 \\\\\n",
    "1 & 1/2 & 0 & 1/2 \\\\\n",
    "2 & 0 & 0 & 1 \\\\\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$g(0) = 1 + .5g(0) + .5g(1)$\n",
    "\n",
    "$g(1) = 1 + .5g(0)$\n",
    "\n",
    "$g(0)=6, g(1)=4$\n",
    "\n",
    "$E_0(V_{TT})=6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "\n",
    "Bob, who has 15 pennies, and Charlie, who has 10 pennies, decide to play a game. They each flip a coin. If the two coins match, Bob gets the two pennies (for a profit of 1). If the two coins are different, then Charlie gets the two pennies. They quit when someone has all the pennies. What is the expected time until someone has all the pennies?\n",
    "\n",
    "Let $\\tau = \\min\\{n: X_n \\in \\{0, N\\}\\}$ be the first time someone has all the pennies. We claim\n",
    "\n",
    "$\n",
    "E_x(\\tau) = x(N-x)\n",
    "$\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "**Case 1 fair game: p = 0.5**\n",
    "\n",
    "$g(N)=0$\n",
    "\n",
    "$g(0)=0$\n",
    "\n",
    "$g(x)=1+0.5g(x+1)+0.5g(x-1)$\n",
    "\n",
    "$g(x+1)-g(x)=g(x)-g(x-1)-2$\n",
    "\n",
    "Set $g(1)-g(0)=c=g(1)$\n",
    "\n",
    "$g(2)-g(1)=c-2\\cdot 1$\n",
    "\n",
    "$g(3)-g(2)=c-2\\cdot 2$\n",
    "\n",
    "$\\vdots$\n",
    "\n",
    "$g(x+1)-g(x)=c-2\\cdot x$\n",
    "\n",
    "$\\sum_{x=0}^{N-1}g(x+1)-g(x)=g(N)-g(0)=0$\n",
    "\n",
    "$\\sum_{x=0}^{N-1}g(x+1)-g(x)=\\sum_{x=0}^{N-1} (c-2\\cdot x)=(N)c-2\\cdot\\frac{(N)(N-1)}{2}=0$\n",
    "\n",
    "$c=N-1$\n",
    "\n",
    "$g(x)-g(0)=(x)\\cdot (N-1)-2\\cdot\\frac{(x)(x-1)}{2}$\n",
    "\n",
    "$g(x)=x(N-x)=E_x\\tau$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2 unfair game: p $\\neq$ 0.5**\n",
    "\n",
    "$p+q=1$\n",
    "\n",
    "$g(N)=0$\n",
    "\n",
    "$g(0)=0$\n",
    "\n",
    "$g(x)=1+pg(x+1)+qg(x-1)$\n",
    "\n",
    "$g(x+1)-g(x)=g(x)-g(x-1)-2$\n",
    "\n",
    "$g(x)=\\frac{x}{q-p}- \\frac{N}{q-p} \\left[ \\frac{1-(q/p)^x}{1-(q/p)^N} \\right]= E_x\\tau$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "\n",
    "For a concrete example of this we can consider roulette. Suppose we bring $50 to a casino with the goal of winning $100 before we go bankrupt. If we bet $1 on red each spin, then \\( p = 18/38 \\) since there are\n",
    "\n",
    "- 18 red spaces\n",
    "- 18 black spaces\n",
    "- 2 green spaces (0 and 00)\n",
    "\n",
    "How long do we expect to play until we reach $100 or go bankrupt?\n",
    "\n",
    "å¥—å…¬å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Infinite State Spaces\n",
    "\n",
    "See ppt MATH_497_DiscreteMarkov7_annotated.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
