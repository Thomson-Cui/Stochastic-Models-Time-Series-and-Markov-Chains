{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.8 (Branching Processes)\n",
    "\n",
    "These processes arose from Francis Galton’s statistical investigation of the extinction of family names. Consider a population in which each individual in the $n$-th generation independently gives birth, producing $k$ children (who are members of generation $n + 1$) with probability $p_k$. In Galton’s application only male children count since only they carry on the family name.\n",
    "\n",
    "To define the Markov chain, note that the number of individuals in generation $n, X_n$, can be any nonnegative integer, so the state space is $\\{0,1,2,...\\}$. If we let $Y_1,Y_2,...$ be independent random variables with $P(Y_m=k)=p_k$,\n",
    "\n",
    "$$p(i,j)=P(Y_1+\\cdots+Y_i=j)\\quad\\mathrm{for~}i>0\\mathrm{~and~}j\\geq0$$\n",
    "\n",
    "When there are no living members of the population, no new ones can be born, so $p(0,0)=1$\n",
    "\n",
    "Q. What is the probability that the line of a man becomes extinct?, i.e., the branching\n",
    "process becomes absorbed at 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.9 (Wright–Fisher Model)\n",
    "Thinking of a population of $N/2$ diploid individuals who have two copies of each of their chromosomes, or of $N$ haploid\n",
    "individuals who have one copy, we consider a fixed population of $N$ genes that can be one of two types: $A$ or $a$. In the simplest version of this model the population at time $n + 1$ is obtained by drawing with replacement from the population at time $n$. In this case, if we let $X_n$ be the number of $A$ alleles at time $n$, then $X_n$ is a Markov Chain with transition probability\n",
    "\n",
    "$$p(i,j)=\n",
    "\\begin{pmatrix}\n",
    "N \\\\\n",
    "j\n",
    "\\end{pmatrix}\\left(\\frac{i}{N}\\right)^j\\left(1-\\frac{i}{N}\\right)^{N-j}$$\n",
    "\n",
    "since the right-hand side is the binomial distribution for $N$ independent trials with success probability $i/N$.\n",
    "\n",
    "In this model the states $x=0$ and $N$ that correspond to fixation of the populationin the all a or all A states are **absorbing states**, that is, $p(x,x)=1$.\n",
    "\n",
    "#### Absorbing state\n",
    "\n",
    "An absorbing state is a special type of state in a Markov chain. Once the system enters this state, it will remain there forever and cannot leave.\n",
    "\n",
    "In a Markov chain with a set of states $S = \\{s_1, s_2, \\dots, s_n\\}$ and a transition probability matrix  $P$, a state $s_i$ is an absorbing state if:\n",
    "$$\n",
    "P(s_i, s_i) = 1 \\quad \\text{and} \\quad P(s_i, s_j) = 0 \\quad \\forall j \\neq i.\n",
    "$$\n",
    "This means:\n",
    "- Once the chain reaches $s_i$, it will stay there with probability 1.\n",
    "- It is impossible to transition from $s_i$ to any other state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Starting from $i$ of the $A$ alleles and $N-i$ of the $a$ alleles, what is the probability that the population fixates in the all $A$ state?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this simple model more realistic we can introduce the possibility of mutations: an $A$ that is drawn ends up being an $a$ in the next generation with probability $u$, while an $a$ that is drawn ends up being an $A$ in the next generation with probability $v$. In this case the probability an $A$ is produced by a given draw is\n",
    "\n",
    "$$\\rho_i=\\frac{i}{N}(1-u)+\\frac{N-i}{N}v$$\n",
    "\n",
    "but the transition probability still has the binomial form\n",
    "\n",
    "$$p(i,j)=\n",
    "\\begin{pmatrix}\n",
    "N \\\\\n",
    "j\n",
    "\\end{pmatrix}(\\rho_i)^j(1-\\rho_i)^{N-j}$$\n",
    "\n",
    "If $u$ and $v$ are both positive, then 0 and $N$ are no longer absorbing states, so we ask:\n",
    "\n",
    "Q2. Does the genetic composition settle down to an equilibrium distribution as time $t\\to\\infty$\n",
    "\n",
    "As the next example shows it is easy to extend the notion of a Markov chain to cover situations in which the future evolution is independent of the past when we know the last two states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.10 (Two-Stage Markov Chains)\n",
    "\n",
    "In a Markov chain the distribution of $X{n+1}$ only depends on $X_n$. This can easily be generalized to case in which the\n",
    "distribution of $X_{n+1}$ only depends on ($X_n,X_{n-1}$). For a concrete example consider a basketball player who makes a shot with the following probabilities:\n",
    "\n",
    "- 1/2 if he has missed the last two times\n",
    "- 2/3 if he has hit one of his last two shots\n",
    "- 3/4 if he has hit both of his last two shots\n",
    "\n",
    "To formulate a Markov chain to model his shooting, we let the states of the process be the outcomes of his last two shots: $\\{HH,HM,MH,MM\\}$\n",
    "\n",
    "|      | HH   | HM   | MH   | MM   |\n",
    "|------|------|------|------|------|\n",
    "| **HH** | 3/4  | 1/4  | 0    | 0    |\n",
    "| **HM** | 0    | 0    | 2/3  | 1/3  |\n",
    "| **MH** | 2/3  | 1/3  | 0    | 0    |\n",
    "| **MM** | 0    | 0    | 1/2  | 1/2  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Multistep Transition Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
