{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 Markov Chains\n",
    "## 1.1 Definitions and Examples\n",
    "\n",
    "### Example 1.1 (Gambler’s Ruin)\n",
    "\n",
    "Consider a gambling game in which on any turn you win $1 with probability $p = 0.4$ or lose $1 with probability $1-p=0.6$. Suppose further that you adopt the rule that you quit playing if your fortune reaches $N. Of course, if your fortune reaches $0 the casino makes you stop.\n",
    "\n",
    "Let $X_n$ be the amount of money you have after $n$ plays, thus $X_n$ has \"**Markov Property**\".\n",
    "\n",
    "Markov Property means that given the current state, $X_n$, any other information about the past is irrelevant for predicting the next state $X_{n+1}$.\n",
    "\n",
    "$$P(X_{n+1}=i+1|X_n=i,X_{n-1}=i{n-1},...,X_0=i_0) = 0.4 = p$$\n",
    "$$P(X_{n+1}=i-1|X_n=i,X_{n-1}=i{n-1},...,X_0=i_0) = 0.6 = 1-p$$\n",
    "\n",
    "where the fortune $X_n=i$ with $0<i<N$, for any possible history of the wealth $i_{n-1},i_{n-2},...,i_1,i_0$.\n",
    "\n",
    "### Discrete time Markov chain\n",
    "\n",
    "We say that $X_n$ is a discrete time Markov chain with **transition matrix** $p(i,j)$ if for $j,i_{n-1},...,i_1,i_0$.\n",
    "\n",
    "$$P(X_{n+1}=j|X_n=i,X_{n-1}=i{n-1},...,X_0=i_0) = p(i,j)\\tag{1.1}$$\n",
    "\n",
    "**The transition probability**\n",
    "\n",
    "$$p(i,j)=P(X_{n+1}=j|X_n=i)$$\n",
    "\n",
    "which does not depend on the time $n$.\n",
    "\n",
    "In the case of the gambler’s ruin chain, the transition probability has\n",
    "\n",
    "$$\\begin{aligned}\n",
    " & p(i,i+1)=0.4,\\quad p(i,i-1)=0.6,\\quad\\mathrm{if~}0<i<N \\\\\n",
    " & p(0,0)=1\\quad p(N,N)=1\n",
    "\\end{aligned}$$\n",
    "\n",
    "When $N = 5$ the matrix is\n",
    "\n",
    "$$\\begin{array}{ccccccc} \n",
    "& \\mathbf{0} & \\mathbf{1} & \\mathbf{2} & \\mathbf{3} & \\mathbf{4} & \\mathbf{5} \\\\\n",
    "\\mathbf{0} & 1.0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\mathbf{1} & 0.6 & 0 & 0.4 & 0 & 0 & 0 \\\\\n",
    "\\mathbf{2} & 0 & 0.6 & 0 & 0.4 & 0 & 0 \\\\\n",
    "\\mathbf{3} & 0 & 0 & 0.6 & 0 & 0.4 & 0 \\\\\n",
    "\\mathbf{4} & 0 & 0 & 0 & 0.6 & 0 & 0.4 \\\\\n",
    "\\mathbf{5} & 0 & 0 & 0 & 0 & 0 & 1.0\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.2 (Ehrenfest Chain)\n",
    "\n",
    "We have two “urns,” i.e., two of the exalted trash cans of probability theory, in which there are a total of N balls. We pick one of the $N$ balls at random and move it to the other urn. Let $X_n$ be the number of balls in the “left” urn after the nth draw. It should be clear that $X_n$ has the Markov property\n",
    "\n",
    "$$P(X_{n+1}=i+1|X_n=i,X_{n-1}=i_{n-1},\\ldots X_0=i_0)=(N-i)/N$$\n",
    "\n",
    "**The transition probability**\n",
    "\n",
    "$$x_i=\n",
    "\\begin{cases}\n",
    "p(i,i+1)=(N-i)/N,\\quad p(i,i-1)=i/N\\quad\\mathrm{for} \\quad 0\\leq i\\leq N\\\\\n",
    "p(i,j)=0\\quad \\mathrm{otherwise}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The definition of Markov chain\n",
    "\n",
    "1. $p(i,j)\\geq 0, since they are probabilities$\n",
    "2. $\\sum_j p(i,j) = 1$, since when $X_n=i, X_{n+1}$ will be in some state $j$. \n",
    "\n",
    "According to the equation in $(2)$, we can get the entries of the matrix are **nonnegative** and each ROW of\n",
    "the matrix sums to 1.\n",
    "\n",
    "**Any matrix with properties (1) and (2) gives rise to a Markov chain, $X_n$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.3 (Weather Chain)\n",
    "\n",
    "Let $X_n$ be the weather on day $n$ in Ithaca, NY, which we assume is either: 1 = rainy, or 2 = sunny. Even though the weather is not exactly a Markov chain, we can propose a Markov chain model for the weather by writing down a transition probability\n",
    "\n",
    "$$\\begin{array}{ccccccc} \n",
    "& \\mathbf{1} & \\mathbf{2}\\\\\n",
    "\\mathbf{1} & 0.6 & 0.4 \\\\\n",
    "\\mathbf{2} & 0.2 & 0.8 \\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. What is the long-run fraction of days that are sunny?\n",
    "\n",
    "see 21\n",
    "\n",
    "https://chatgpt.com/share/67876dcb-4c90-8006-8ffe-8834e23eb576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.5 (Brand Preference) \n",
    "Suppose there are three types of laundry detergent, 1, 2, and 3, and let $X_n$ be the brand chosen on the $n$-th purchase. Customers who try these brands are satisfied and choose the same thing again with probabilities 0.8, 0.6, and 0.4, respectively. When they change they pick one of the other two brands at random. The transition probability is\n",
    "\n",
    "$$\\begin{array}{ccccccc} \n",
    "& \\mathbf{1} & \\mathbf{2} & \\mathbf{3}\\\\\n",
    "\\mathbf{1} & 0.8 & 0.1 & 0.1\\\\\n",
    "\\mathbf{2} & 0.2 & 0.6 & 0.2 \\\\\n",
    "\\mathbf{3} & 0.3 & 0.3 & 0.4 \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "Q. Do the market shares of the three product stabilize?\n",
    "\n",
    "https://chatgpt.com/c/67876d21-e728-8006-bbba-95559f0ca028"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.6 (Inventory Chain)\n",
    "\n",
    "We will consider the consequences of using an $s$, $S$ inventory control policy. That is, when the stock on hand at the end of the day falls to $s$ or below, we order enough to bring it back up to $S$. For simplicity, we suppose happens at the beginning of the next day. Let $X_n$ be the amount of stock on hand at the end of day $n$ and $D_{n+1}$ be the demand on day $n+1$. Introducing notation for the positive part of a real number,\n",
    "\n",
    "$$x^+=\\max\\{x,0\\}=\n",
    "\\begin{cases}\n",
    "x & \\mathrm{if}\\quad x>0 \\\\\n",
    "0 & \\mathrm{if}\\quad x\\leq0 & \n",
    "\\end{cases}$$\n",
    "\n",
    "then we can write the chain in general as\n",
    "\n",
    "$$X_{n+1}=\n",
    "\\begin{cases}\n",
    "(X_n-D_{n+1})^+ & \\mathrm{if}X_n>s \\\\\n",
    "(S-D_{n+1})^+ & \\mathrm{if}X_n\\leq s & \n",
    "\\end{cases}$$\n",
    "\n",
    "Suppose now that an electronics store sells a video game system and uses an inventory policy with $s = 1, S = 5$. That is, if at the end of the day, the number of units they have on hand is $1$ or $0$, they order enough new units so their total on hand at the beginning of the next day is $5$. If we assume that\n",
    "\n",
    "$$\\begin{array}\n",
    "{ccccc}\\text{for } k= & 0 & 1 & 2 & 3 \\\\\n",
    "P(D_{n+1}=k) & .3 & .4 & .2 & .1\n",
    "\\end{array}$$\n",
    "\n",
    "then we have the following transition matrix:\n",
    "\n",
    "$$\\begin{array}{ccccccc} \n",
    "& \\mathbf{0} & \\mathbf{1} & \\mathbf{2} & \\mathbf{3} & \\mathbf{4} & \\mathbf{5} \\\\\n",
    "\\mathbf{0} & 0 & 0 & 0.1 & 0.2 & 0.4 & 0.3 \\\\\n",
    "\\mathbf{1} & 0 & 0 & 0.1 & 0.2 & 0.4 & 0.3 \\\\\n",
    "\\mathbf{2} & 0.3 & 0.4 & 0.3 & 0 & 0 & 0 \\\\\n",
    "\\mathbf{3} & 0.1 & 0.2 & 0.4 & 0.3 & 0 & 0 \\\\\n",
    "\\mathbf{4} & 0 & 0.1 & 0.2 & 0.4 & 0.3 & 0 \\\\\n",
    "\\mathbf{5} & 0 & 0 & 0.1 & 0.2 & 0.4 & 0.3\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Suppose we make $12 profit on each unit sold but it costs $2 a day to store items. What is the long-run profit per day of this inventory policy? How do we choose $s$ and $S$ to maximize profit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.7 (Repair Chain)\n",
    " \n",
    "A machine has three critical parts that are subject to failure, but can function as long as two of these parts are working. When two are broken, they are replaced and the machine is back to working order the next day. To formulate a Markov chain model we declare its state space to be the parts that are broken $\\{0, 1, 2, 3, 12, 13, 23\\}$. If we assume that parts 1, 2, and 3 fail with probabilities .01, .02, and .04, but no two parts fail on the same day, then we arrive\n",
    "at the following transition matrix:\n",
    "\n",
    "$$\\begin{array}{cccccccc} \n",
    "& \\mathbf{0} & \\mathbf{1} & \\mathbf{2} & \\mathbf{3} & \\mathbf{12} & \\mathbf{13} & \\mathbf{23} \\\\\n",
    "\\mathbf{0} & 0.93 & 0.01 & 0.02 & 0.04 & 0 & 0 & 0 \\\\\n",
    "\\mathbf{1} & 0 & 0.94 & 0 & 0 & 0.02 & 0.04 & 0 \\\\\n",
    "\\mathbf{2} & 0 & 0 & 0.95 & 0 & 0.01 & 0 & 0.04 \\\\\n",
    "\\mathbf{3} & 0 & 0 & 0 & 0.97 & 0 & 0.01 & 0.02 \\\\\n",
    "\\mathbf{12} & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\mathbf{13} & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\mathbf{23} & 1 & 0 & 0 & 0 & 0 & 0 & 0\n",
    "\\end{array}$$\n",
    "\n",
    "Q. If we are going to operate the machine for 1800 days (about 5 years), then how many parts of types 1, 2, and 3 will we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.8 (Branching Processes).\n",
    "\n",
    "These processes arose from Francis Galton’s statistical investigation of the extinction of family names. Consider a population in which each individual in the nth generation independently gives birth, producing $k$ children (who are members of generation $n$ + 1) with probability $p_k$. In Galton’s application only male children count since only they carry on the family name.\n",
    "\n",
    "To define the Markov chain, note that the number of individuals in generation $n$, $X_n$, can be any nonnegative integer, so the state space is $\\{0, 1, 2...\\}$. If we let $Y_1, Y_2...$ be independent random variables with $P(Y_m = k) = p_k$, then we can write the transition probability as\n",
    "\n",
    "$$p(i,j)=P(Y_1+\\cdots+Y_i=j)\\quad\\text{for }i>0\\text{ and }j\\geq0$$\n",
    "\n",
    "When there are no living members of the population, no new ones can be born, so $p(0,0)=1$.\n",
    "\n",
    "Q. What is the probability that the line of a man becomes extinct?, i.e., the branching process becomes absorbed at 0?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
